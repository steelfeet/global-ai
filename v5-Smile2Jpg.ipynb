{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import tqdm\n",
    "from typing import Optional\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from rdkit import Chem\n",
    "import rdkit.Chem.Draw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"Z:\\\\Dropbox\\\\www\\\\studs.steelfeet.ru\\\\_hack\\\\2021-22\\\\global-ai\")\n",
    "DATA_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "\n",
    "\n",
    "TRAIN_DIR = Path(\"D:\\\\_hack\\\\2021-22\\\\global-ai\\\\train\")\n",
    "#исходные, неаугментированные изображения\n",
    "TRAIN_DIR_1 = Path(\"D:\\\\_hack\\\\2021-22\\\\global-ai\\\\no_aug\")\n",
    "\n",
    "MODEL_FILENAME = \"v5-mobilenet_v3_large-pretrained.pth\"\n",
    "VALID_PART = 0.1\n",
    "BATCH = 128\n",
    "EPOCHS = 10\n",
    "LR = 0.01\n",
    "IM_SIZE = 600\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 5351 0.03849747710708279\n",
      "5351 5351 1.0\n"
     ]
    }
   ],
   "source": [
    "# добавляем аугментированные картинки\n",
    "# https://github.com/aleju/imgaug\n",
    "# https://nbviewer.org/github/aleju/imgaug-doc/blob/master/notebooks/A01%20-%20Load%20and%20Augment%20an%20Image.ipynb\n",
    "# https://imgaug.readthedocs.io/en/latest/source/examples_basics.html\n",
    "import random\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.7, 0.9), \"y\": (0.6, 0.8)}, \n",
    "        rotate=(-25, 25)),\n",
    "    #iaa.AdditiveGaussianNoise(scale=(10, 60)),\n",
    "    #https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.ElasticTransformation\n",
    "    iaa.ElasticTransformation(alpha=10, sigma=9),\n",
    "    #iaa.AddToHueAndSaturation(60)\n",
    "], random_order=True)\n",
    "\n",
    "\n",
    "data_active_noaug = []\n",
    "data_active = []\n",
    "data_no_active = []\n",
    "n = 1\n",
    "with open(DATA_DIR.joinpath(DATA_FILE), 'r') as file_name:\n",
    "    reader = csv.DictReader(file_name)\n",
    "    for row in reader:\n",
    "        if (row[\"Active\"] == \"True\"):\n",
    "            data_active.append((n, row[\"Smiles\"]))\n",
    "            data_active_noaug.append((n, row[\"Smiles\"]))\n",
    "\n",
    "            mol = Chem.MolFromSmiles(row[\"Smiles\"])\n",
    "\n",
    "            noaug_class_path = Path(TRAIN_DIR_1, \"1\")\n",
    "            rdkit.Chem.Draw.MolToFile(mol, Path(noaug_class_path, str(n)+\".png\"), imageType=\"png\")\n",
    "\n",
    "            aug_class_path = Path(TRAIN_DIR, \"1\")\n",
    "            rdkit.Chem.Draw.MolToFile(mol, Path(aug_class_path, str(n)+\".png\"), imageType=\"png\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            data_no_active.append((n, row[\"Smiles\"]))\n",
    "\n",
    "            noaug_class_path = Path(TRAIN_DIR_1, \"0\", str(n)+\".png\")\n",
    "            mol = Chem.MolFromSmiles(row[\"Smiles\"])\n",
    "            rdkit.Chem.Draw.MolToFile(mol, Path(noaug_class_path), imageType=\"png\")\n",
    "            \n",
    "            # все неактивные тоже аугментированные\n",
    "            image = imageio.imread(noaug_class_path)\n",
    "            image_aug = seq(image=image)        \n",
    "            imageio.imwrite(Path(TRAIN_DIR, \"0\", str(n) + \".png\"), image_aug)\n",
    "\n",
    "        \n",
    "        n += 1\n",
    "print(len(data_active_noaug), len(data_no_active), len(data_active_noaug) / len(data_no_active))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(n, n + (len(data_no_active) - len(data_active_noaug))):\n",
    "    line = random.choice(data_active_noaug)\n",
    "    file_n, smile = line\n",
    "    noaug_class_path = Path(TRAIN_DIR_1, \"1\", str(file_n)+\".png\")\n",
    "    image = imageio.imread(noaug_class_path)\n",
    "\n",
    "    image_aug = seq(image=image)        \n",
    "    imageio.imwrite(Path(TRAIN_DIR, \"1\", str(i) + \".png\"), image_aug)\n",
    "\n",
    "    data_active.append((i, smile))\n",
    "    \n",
    "\n",
    "print(len(data_active), len(data_no_active), len(data_active) / len(data_no_active))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формируем Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load image success, X_Train count: 10702\n"
     ]
    }
   ],
   "source": [
    "X_Train = []\n",
    "Y_Train = []\n",
    "NUM_CL = 0\n",
    "for label_name in sorted(TRAIN_DIR.glob('*/')):\n",
    "    if label_name.is_dir():\n",
    "        class_dir = Path(TRAIN_DIR, label_name.name) #директория класса\n",
    "        all_image_paths = list(class_dir.glob('*/'))\n",
    "        for path in all_image_paths:\n",
    "            X_Train.append(str(path))\n",
    "            Y_Train.append(NUM_CL)\n",
    "        NUM_CL = NUM_CL + 1\n",
    "\n",
    "print(\"load image success, X_Train count:\", str(len(X_Train)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Resize((IM_SIZE, IM_SIZE)),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "\n",
    "class GetData(Dataset):\n",
    "    def __init__(self, Dir, FNames, Labels, Transform):\n",
    "        self.dir = Dir\n",
    "        self.fnames = FNames\n",
    "        self.transform = Transform\n",
    "        self.labels = Labels         \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "    def __getitem__(self, index):       \n",
    "        x = Image.open(self.fnames[index])\n",
    "        x = x.convert('RGB')\n",
    "    \n",
    "        if \"train\" in self.dir:             \n",
    "            return self.transform(x), self.labels[index]\n",
    "        elif \"test\" in self.dir:            \n",
    "            return self.transform(x), self.fnames[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = GetData(str(TRAIN_DIR), X_Train, Y_Train, Transform)\n",
    "train_size = int((1 - VALID_PART) * len(train_set))\n",
    "valid_size = len(train_set) - train_size\n",
    "train_set, valid_set = random_split(train_set,[train_size,valid_size])\n",
    "\n",
    "trainloader = DataLoader(train_set, batch_size=BATCH, shuffle=True)\n",
    "validloader = DataLoader(valid_set, batch_size=BATCH, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainloader shape: \n",
      "torch.Size([128, 3, 600, 600])\n",
      "\n",
      "device:  cpu\n",
      "\n",
      "prev features: \n",
      "960\n",
      "1280\n"
     ]
    }
   ],
   "source": [
    "print(\"trainloader shape: \")\n",
    "print(next(iter(trainloader))[0].shape)\n",
    "\n",
    "print()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"device: \", device)\n",
    "\n",
    "model = torchvision.models.mobilenet_v3_large(pretrained=True)\n",
    "print()\n",
    "# print(model)\n",
    "# print()\n",
    "print(\"prev features: \")\n",
    "print(model.classifier[0].in_features) \n",
    "print(model.classifier[0].out_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Перенастраиваем модель под наши классы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new features: \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "n_inputs = model.classifier[0].in_features\n",
    "last_layer = nn.Linear(n_inputs, NUM_CL)\n",
    "model.classifier = last_layer\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# print()\n",
    "# print(model)\n",
    "print(\"new features: \")\n",
    "print(model.classifier.out_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройки обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters())\n",
    "\n",
    "training_history = {'accuracy':[],'loss':[]}\n",
    "validation_history = {'accuracy':[],'loss':[]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [28:37<00:00, 22.60s/it]\n",
      "100%|██████████| 9/9 [02:44<00:00, 18.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Acc: 56.385624 | Train Loss: 0.677314 | Valid Acc: 48.358078 | Valid Loss: 0.774146\n",
      "Validation Loss Decreased(inf--->0.774146) \t Saving The Model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [24:43<00:00, 19.52s/it]\n",
      "100%|██████████| 9/9 [02:44<00:00, 18.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Acc: 56.201916 | Train Loss: 0.678282 | Valid Acc: 57.110668 | Valid Loss: 0.667964\n",
      "Validation Loss Decreased(0.774146--->0.667964) \t Saving The Model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [24:41<00:00, 19.50s/it]\n",
      "100%|██████████| 9/9 [02:45<00:00, 18.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Acc: 60.371460 | Train Loss: 0.657979 | Valid Acc: 60.510857 | Valid Loss: 0.657353\n",
      "Validation Loss Decreased(0.667964--->0.657353) \t Saving The Model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [24:41<00:00, 19.49s/it]\n",
      "100%|██████████| 9/9 [02:45<00:00, 18.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Acc: 61.975407 | Train Loss: 0.648040 | Valid Acc: 61.803703 | Valid Loss: 0.650946\n",
      "Validation Loss Decreased(0.657353--->0.650946) \t Saving The Model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [24:41<00:00, 19.50s/it]\n",
      "100%|██████████| 9/9 [02:44<00:00, 18.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Acc: 64.189507 | Train Loss: 0.638180 | Valid Acc: 61.827721 | Valid Loss: 0.645886\n",
      "Validation Loss Decreased(0.650946--->0.645886) \t Saving The Model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [24:41<00:00, 19.49s/it]\n",
      "100%|██████████| 9/9 [02:44<00:00, 18.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Acc: 64.676292 | Train Loss: 0.632128 | Valid Acc: 62.198948 | Valid Loss: 0.633584\n",
      "Validation Loss Decreased(0.645886--->0.633584) \t Saving The Model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [24:40<00:00, 19.48s/it]\n",
      "100%|██████████| 9/9 [02:44<00:00, 18.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Acc: 65.606758 | Train Loss: 0.625804 | Valid Acc: 64.769867 | Valid Loss: 0.633135\n",
      "Validation Loss Decreased(0.633584--->0.633135) \t Saving The Model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [24:40<00:00, 19.48s/it]\n",
      "100%|██████████| 9/9 [02:45<00:00, 18.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Acc: 66.286545 | Train Loss: 0.618916 | Valid Acc: 64.162231 | Valid Loss: 0.625069\n",
      "Validation Loss Decreased(0.633135--->0.625069) \t Saving The Model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [24:40<00:00, 19.48s/it]\n",
      "100%|██████████| 9/9 [02:44<00:00, 18.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Acc: 66.527954 | Train Loss: 0.616308 | Valid Acc: 65.599144 | Valid Loss: 0.619713\n",
      "Validation Loss Decreased(0.625069--->0.619713) \t Saving The Model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [24:39<00:00, 19.47s/it]\n",
      "100%|██████████| 9/9 [02:44<00:00, 18.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Acc: 66.868172 | Train Loss: 0.612954 | Valid Acc: 66.404404 | Valid Loss: 0.617077\n",
      "Validation Loss Decreased(0.619713--->0.617077) \t Saving The Model\n",
      "\n",
      "\n",
      "success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_valid_loss = np.inf\n",
    " \n",
    "for e in range(EPOCHS):\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    for data, labels in tqdm.tqdm(trainloader):\n",
    "        # Transfer Data to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = model(data)\n",
    "        # Find the Loss\n",
    "        loss = criterion(target,labels)\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "        # Calculate Accuracy\n",
    "        acc = ((target.argmax(dim=1) == labels).float().mean())\n",
    "        train_acc += acc\n",
    "    train_acc = train_acc / len(trainloader) * 100\n",
    "    train_loss = train_loss / len(trainloader)        \n",
    "     \n",
    "    valid_acc = 0.0\n",
    "    valid_loss = 0.0\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in tqdm.tqdm(validloader):\n",
    "        # Transfer Data to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "         \n",
    "        # Forward Pass\n",
    "        target = model(data)\n",
    "        # Find the Loss\n",
    "        loss = criterion(target,labels)\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "        # Calculate Accuracy\n",
    "        acc = ((target.argmax(dim=1) == labels).float().mean())\n",
    "        valid_acc += acc\n",
    "    valid_acc = valid_acc / len(validloader) * 100\n",
    "    valid_loss = valid_loss / len(validloader)\n",
    " \n",
    "    print(f'Epoch {e+1} | Train Acc: {train_acc:.6f} | Train Loss: {train_loss:.6f} | Valid Acc: {valid_acc:.6f} | Valid Loss: {valid_loss:.6f}')\n",
    "     \n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), str(Path(\"models\", MODEL_FILENAME)))\n",
    "\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = str(Path(\"D:\\\\_hack\\\\2021-22\\\\global-ai\\\\test\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "X_Test = []\n",
    "\n",
    "with open(DATA_DIR.joinpath(TEST_FILE), 'r') as file_name:\n",
    "    reader = csv.DictReader(file_name)\n",
    "    for row in reader:\n",
    "        out_file = str(Path(TEST_DIR, str(n)+\".png\"))\n",
    "        X_Test.append(out_file)\n",
    "\n",
    "        #mol = Chem.MolFromSmiles(row[\"Smiles\"])\n",
    "        #rdkit.Chem.Draw.MolToFile(mol, out_file, imageType=\"png\")\n",
    "\n",
    "        n += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем веса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load state dict:\n",
      "\n",
      "success\n",
      "testset len: 1614\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Load state dict:\")\n",
    "model.load_state_dict(torch.load(str(Path(\"models\", MODEL_FILENAME))))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Подготавливаем загрузчик иображений\n",
    "testset = GetData(TEST_DIR, X_Test, None, Transform)\n",
    "testloader = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "print()\n",
    "print(\"success\")\n",
    "print(\"testset len:\", str(len(testset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аугментируем тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.7, 0.9), \"y\": (0.6, 0.8)}, \n",
    "        rotate=(-25, 25)),\n",
    "    #iaa.AdditiveGaussianNoise(scale=(10, 60)),\n",
    "    #https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.ElasticTransformation\n",
    "    iaa.ElasticTransformation(alpha=10, sigma=9),\n",
    "    #iaa.AddToHueAndSaturation(60)\n",
    "], random_order=True)\n",
    "\n",
    "\n",
    "X_test = []\n",
    "n = 1\n",
    "with open(DATA_DIR.joinpath(TEST_FILE), 'r') as file_name:\n",
    "    reader = csv.DictReader(file_name)\n",
    "    for row in reader:\n",
    "        test_class_path = Path(TEST_DIR, str(n)+\".png\")\n",
    "        mol = Chem.MolFromSmiles(row[\"Smiles\"])\n",
    "        rdkit.Chem.Draw.MolToFile(mol, Path(test_class_path), imageType=\"png\")\n",
    "      \n",
    "        image = imageio.imread(test_class_path)\n",
    "        image_aug = seq(image=image)        \n",
    "        imageio.imwrite(Path(TEST_DIR, str(n) + \".png\"), image_aug)\n",
    "\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распознаем\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "i = 1\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for image, fname in testloader:\n",
    "        logits = model(image)        \n",
    "        ps = torch.exp(logits)        \n",
    "        _, top_class = ps.topk(1, dim=1)\n",
    "        \n",
    "        for pred in top_class:\n",
    "            image_n = int(fname[0].split('\\\\')[-1][:-4])\n",
    "            y_test.append([image_n, pred.item()])\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраняем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \",Active\\n\"\n",
    "n = 1\n",
    "for y_pred in y_test:\n",
    "  \n",
    "  if (y_pred[0] == 0):\n",
    "    text = text + str(n) + \",False\\n\"\n",
    "  else:\n",
    "    text = text + str(n) + \",True\\n\"\n",
    "  \n",
    "  n+=1\n",
    "\n",
    "file = open('submission.csv', 'w')\n",
    "file.write(text)\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
